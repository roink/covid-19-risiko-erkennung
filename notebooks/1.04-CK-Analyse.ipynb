{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "944848ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()))\n",
    "from src.load_covid19 import load_clean_covid19\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22b33692",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "file_path = os.path.join(os.path.dirname(current_dir), \"data\", \"raw\", \"covid19-dataset\", \"Covid Data.csv\")\n",
    "df = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0798ac3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores(y_test, y_pred):\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    prec = precision_score(y_test, y_pred)\n",
    "    rec = recall_score(y_test, y_pred)\n",
    "    return acc, f1, prec, rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e10b88b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wir fügen zuerst ein neues Attribut hinzu, das angibt, ob die Person gestorben ist oder nicht. \n",
    "#Die Verschlüsselung erfolgt konsistent mit den anderen Attributen (2 für \"nein\", 1 für \"ja\").\n",
    "#Das Todesdatum wird als Attribut verworfen. \n",
    "\n",
    "df['DIED'] = [2 if i=='9999-99-99' else 1 for i in df.DATE_DIED]\n",
    "df=df.drop(columns='DATE_DIED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7705aa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eine Analyse der Missing Values zeigt, dass diese vor allem in den Spalten \"PREGNANT\", \"ICU\" und \"INTUBED\" vorkommen.\n",
    "#Das Attribut \"PREGNANT\" wird bei allen männlichen Patienten auf 2 gesetzt.\n",
    "#Das Attribut \"PATIENT_TYPE\" gibt an, ob die Person hospitalisiert war oder nicht. Bei allen Patienten ohne\n",
    "#Krankenhausaufenthalt kann das Attribut \"ICU\" auf 2 gesetzt werden, da keiner dieser Patienten folglich auf\n",
    "#einer Intensivstation behandelt wurde. \n",
    "#Dieselbe Vorgehensweise wenden wir auf das Attribut \"INTUBED\" an. Dazu gehen wir von der Grundannahme aus, dass\n",
    "#ein Anschluss an ein Beatmungsgerät im Rahmen eines Klinikaufenthaltes erfolgt. Etwaige Fälle von Heimintubation \n",
    "#vernachlässigen wir dabei. \n",
    "\n",
    "df.loc[df.SEX==2,'PREGNANT']=2\n",
    "df.loc[df.PATIENT_TYPE==1,'ICU']=2\n",
    "df.loc[df.PATIENT_TYPE==1,'INTUBED']=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a4c8dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Für die anderen fehlenden Werte können keine sinnvollen Aussagen getroffen werden. Da sie nur einen sehr kleinen\n",
    "#Anteil des gesamten Datensatzes ausmachen (2.76%), verwerfen wir sie. \n",
    "\n",
    "for col in df.columns.drop('AGE'):\n",
    "    for i in [97,98, 99]:\n",
    "        df[col]=df[col].replace(i , np.nan)\n",
    "\n",
    "df=df.dropna()\n",
    "df=df.astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8bcc873",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Als Zielvariable wählen wir uns 'DIED' aus.\n",
    "#Wir testen die übrigen Attribute auf Korrelation mit der Zielvariablen und verwerfen\n",
    "#alle Attribute, die unter einem gewissen Schwellwert liegen. (->andere Feature Selection Methoden ausprobieren)\n",
    "\n",
    "target='DIED'\n",
    "threshold=0.04\n",
    "selected_features=df.corr()[target][abs(df.corr()[target])>threshold].index\n",
    "df=df[selected_features]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4dfa2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Wir teilen den Datensatz in Trainings- und Testdatensatz auf. \n",
    "\n",
    "test_size=0.2\n",
    "train, test = train_test_split(df, test_size=test_size, shuffle=True)\n",
    "\n",
    "train_y = train[target]\n",
    "train_x = train.drop(target,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29fb6c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Da die Werte der Zielvariablen unbalanciert sind, wenden wir ein SMOTE-Oversampling an,\n",
    "#um ein balanciertes Trainingsset zu erreichen. (-> auch Undersampling probieren)\n",
    "\n",
    "sm = SMOTE()\n",
    "train_x, train_y = sm.fit_resample(train_x, train_y)\n",
    "\n",
    "test_y = test[target]\n",
    "test_x = test.drop(target,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "969e85fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Klassifikator: GaussianNB\n",
      "\n",
      "Accuracy: 0.8898516186609393\n",
      "F1: 0.5266861922922944\n",
      "Precision: 0.38215508806262233\n",
      "Recall: 0.8470349034225686\n",
      "\n",
      "Klassifikator: DecisionTreeClassifier\n",
      "\n",
      "Accuracy: 0.9279619877019035\n",
      "F1: 0.5699481865284974\n",
      "Precision: 0.5016489745439555\n",
      "Recall: 0.6597763470010166\n",
      "\n",
      "Klassifikator: LogisticRegression\n",
      "\n",
      "Accuracy: 0.8979964106034305\n",
      "F1: 0.5640456031519826\n",
      "Precision: 0.4082703801462334\n",
      "Recall: 0.9120298203998645\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Wir wenden drei \"herkömmliche\" Methoden zum maschinellen Lernen eines Klassifikators an:\n",
    "#Naive Bayes, Entscheidungsbäume bzw. Random Forests und die Logistische Regression. \n",
    "#(->verschiedene Parameter für die Klassifier ausprobieren und optimieren)\n",
    "#(->SVM und KNN eventuell auch ausprobieren)\n",
    "\n",
    "for clf in [GaussianNB(),DecisionTreeClassifier(),LogisticRegression(max_iter=500)]:\n",
    "    #if clf==LogisticRegression():\n",
    "        #train_x = StandardScaler().fit(train_x)\n",
    "        #test_x  = StandardScaler().fit(test_x)\n",
    "    clf.fit(train_x,train_y)\n",
    "    y_pred=clf.predict(test_x)\n",
    "    acc, f1, prec, rec = get_scores(test_y, y_pred)\n",
    "    print(f\"Klassifikator: \"+type(clf).__name__+\"\\n\")\n",
    "    print(f'Accuracy: {acc}')\n",
    "    print(f'F1: {f1}')\n",
    "    print(f'Precision: {prec}')\n",
    "    print(f'Recall: {rec}'+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c46e0b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Covid-19-Risikoerkennung",
   "language": "python",
   "name": "covid-19-risikoerkennung"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

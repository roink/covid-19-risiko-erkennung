---
title: "Covid19: Causal Analysis & Search Trends"
author: "Florian Endel"
date: "`r Sys.Date()`"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning=FALSE, cache=FALSE)

rm(list=ls())

library(tidyverse)
library(lubridate)
library(viridis)
#library(devtools)
#devtools::install_github("PMassicotte/gtrendsR") # installation from github necessary
library(gtrendsR)
library(forecast)
library(jtools)
library(sandwich)

library(tidymodels)
library(themis)  # dealing with class imbalance 

theme_set(theme_light())


## directories
dirs <- list()

dirs$project <- getwd()

# in case dirs$project ends with notebooks, remove notebooks
if (grepl("notebooks$", dirs$project)) {
  dirs$project <- dirname(dirs$project)
}

dirs$notebooks <- file.path(dirs$project, 'notebooks')
dirs$models <- file.path(dirs$project, 'models')
dirs$data <- file.path(dirs$project, 'data')
dirs$data_raw <- file.path(dirs$data, 'raw')
dirs$data_interim <- file.path(dirs$data, 'interim')
dirs$data_processed <- file.path(dirs$data, 'processed')

dirs$trends <- file.path(dirs$data_raw, 'Trends')

# Create directories if they don't exist
dirs$models <- file.path(dirs$data_processed, "models")
if (!dir.exists(dirs$models)) dir.create(dirs$models, recursive = TRUE)

# Clean cache function (optional)
clean_model_cache <- function() {
  cache_files <- list.files(dirs$models, full.names = TRUE)
  file.remove(cache_files)
  cat("Cleaned", length(cache_files), "cached model files\n")
}

# Use this when you want to refit all models:
# clean_model_cache()

dir.create(dirs$trends, showWarnings = FALSE)

# source helper functions
source(file.path(dirs$project, 'src', 'helper_functions.R'))


# load data
files <- list()

```

```{r data_kaggle}

files$kaggle <- file.path(dirs$data_raw, 'covid19-dataset', 'Covid Data.csv')
kaggle_raw <- read_csv(files$kaggle, 
                  col_types = cols(
                    USMER = col_integer(),
                    MEDICAL_UNIT = col_integer(),
                    SEX = col_integer(),
                    PATIENT_TYPE = col_integer(),
                    DATE_DIED = col_character(),
                    INTUBED = col_integer(),
                    PNEUMONIA = col_integer(),
                    AGE = col_integer(),
                    PREGNANT = col_integer(),
                    DIABETES = col_integer(),
                    COPD = col_integer(),
                    ASTHMA = col_integer(),
                    INMSUPR = col_integer(),
                    HIPERTENSION = col_integer(),
                    OTHER_DISEASE = col_integer(),
                    CARDIOVASCULAR = col_integer(),
                    OBESITY = col_integer(),
                    RENAL_CHRONIC = col_integer(),
                    TOBACCO = col_integer(),
                    CLASIFFICATION_FINAL = col_integer(),
                    ICU = col_integer()
                  ))

# Define boolean columns
bool_columns <- c('PNEUMONIA', 'PREGNANT', 'DIABETES', 'COPD', 'ASTHMA', 'INMSUPR',
                 'HIPERTENSION', 'CARDIOVASCULAR', 'RENAL_CHRONIC', 'OTHER_DISEASE', 
                 'OBESITY', 'TOBACCO', 'INTUBED', 'ICU')

missing_values <- c(97, 99)

# Transform the data
kaggle <- kaggle_raw %>%
  # Convert boolean columns
  mutate(across(all_of(bool_columns), 
                ~case_when(
                  . %in% missing_values ~ NA,
                  . == 1 ~ TRUE,
                  . == 2 ~ FALSE
                ))) %>%
  # Convert SEX to categorical
  mutate(
    SEX = case_when(
      SEX == 1 ~ "female",
      SEX == 2 ~ "male",
      TRUE ~ NA_character_
    ),
    SEX = factor(SEX)
  ) %>%
  
  # Convert PATIENT_TYPE to categorical
  mutate(
    PATIENT_TYPE = case_when(
      PATIENT_TYPE == 1 ~ "returned home",
      PATIENT_TYPE == 2 ~ "hospitalization",
      TRUE ~ NA_character_
    ),
    PATIENT_TYPE = factor(PATIENT_TYPE)
  ) %>%
  
  # Handle DATE_DIED column
  mutate(
    DATE_DIED = na_if(DATE_DIED, "9999-99-99"),
    DATE_DIED = as.Date(DATE_DIED, format = "%d/%m/%Y"),
    DIED = !is.na(DATE_DIED)
  ) 
  

#str(kaggle)

```


# Exploratory Data Analysis

```{r data_summary}

# Demographic Variables
## Age
age_summary <- kaggle %>%
  summarize(
    Mean = mean(AGE, na.rm = TRUE),
    Median = median(AGE, na.rm = TRUE),
    SD = sd(AGE, na.rm = TRUE),
    Min = min(AGE, na.rm = TRUE),
    Max = max(AGE, na.rm = TRUE)
  ) %>%
  kable(digits = 2) %>%
  kable_styling()

age_plot <- ggplot(kaggle, aes(x = AGE)) +
  geom_histogram(binwidth = 5, fill = "steelblue", alpha = 0.7) +
  theme_minimal() +
  labs(title = "Age Distribution",
       x = "Age",
       y = "Count")

## Sex
sex_table <- create_freq_table(kaggle, "SEX")
sex_plot <- plot_categorical(kaggle, "SEX")

# Create plots for all boolean variables
bool_plots <- map(bool_columns, ~{
  plot_boolean(kaggle, .x)
})

# Arrange plots in a grid
bool_grid <- plot_grid(plotlist = bool_plots, ncol = 3)

# Patient Type
patient_type_table <- create_freq_table(kaggle, "PATIENT_TYPE")
patient_type_plot <- plot_categorical(kaggle, "PATIENT_TYPE")

# Classification Final
classification_table <- kaggle %>%
  count(CLASIFFICATION_FINAL) %>%
  mutate(Percentage = n/sum(n)*100) %>%
  kable() %>%
  kable_styling()

```


## Demographic Variables

### Age Distribution
```{r age-analysis}
age_summary
age_plot
```

### Sex Distribution
```{r sex-analysis}
sex_table
sex_plot
```

## Medical Conditions
```{r boolean-vars, fig.height=12, fig.width=12}
bool_grid
```

## Patient Management
```{r patient-type}
patient_type_table
patient_type_plot
```


```{r modeling_prep}
set.seed(123)    # for reproducibility

# identify predictors and remove variables we don't want to use
model_data <- kaggle %>%
  # Remove variables we don't want as predictors
  select(-CLASIFFICATION_FINAL,    # This is the COVID test result
         -DATE_DIED,               # This was used to create DIED
         -USMER,                   # Medical unit identifier
         -MEDICAL_UNIT            # Type of medical unit
  ) %>%
  # Ensure all categorical variables are factors
  mutate(
    SEX = factor(SEX),
    PATIENT_TYPE = factor(PATIENT_TYPE),
    # Convert our outcome variables to factors
    DIED = factor(DIED, levels = c(FALSE, TRUE)),
    INTUBED = factor(INTUBED, levels = c(FALSE, TRUE)),
    ICU = factor(ICU, levels = c(FALSE, TRUE))
  )

# Let's create three separate splits for our three different outcomes
# This ensures we have stratified sampling for each outcome
split_died <- initial_split(model_data, strata = DIED)
split_intubed <- initial_split(model_data, strata = INTUBED)
split_icu <- initial_split(model_data, strata = ICU)

# Create training and testing sets
train_died <- training(split_died)
test_died <- testing(split_died)

train_intubed <- training(split_intubed)
test_intubed <- testing(split_intubed)

train_icu <- training(split_icu)
test_icu <- testing(split_icu)

# Create recipe for death prediction
recipe_died <- recipe(DIED ~ ., data = train_died) %>%
  step_rm(INTUBED, ICU) %>%  # Remove other outcome variables
  step_dummy(all_nominal_predictors()) %>%
  step_zv(all_predictors()) %>%  # Remove zero-variance predictors
  step_normalize(all_numeric_predictors())

# Create recipe for intubation prediction
recipe_intubed <- recipe(INTUBED ~ ., data = train_intubed) %>%
  step_rm(DIED, ICU) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_zv(all_predictors()) %>%
  step_normalize(all_numeric_predictors())

# Create recipe for ICU prediction
recipe_icu <- recipe(ICU ~ ., data = train_icu) %>%
  step_rm(DIED, INTUBED) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_zv(all_predictors()) %>%
  step_normalize(all_numeric_predictors())

# Create cross-validation folds
folds_died <- vfold_cv(train_died, v = 5, strata = DIED)
folds_intubed <- vfold_cv(train_intubed, v = 5, strata = INTUBED)
folds_icu <- vfold_cv(train_icu, v = 5, strata = ICU)

```

## COVID-19 Classification

classification: covid test findings. Values 1-3 mean that the patient was diagnosed with covid in different degrees. 4 or higher means that the patient is not a carrier of covid or that the test is inconclusive.

```{r classification}
classification_table
```

```{r covid_classification_modified}
kaggle <- kaggle %>%
  mutate(
    covid_tested = CLASIFFICATION_FINAL <= 3,
    covid_tested_degree = case_when(
      CLASIFFICATION_FINAL == 1 ~ "1",
      CLASIFFICATION_FINAL == 2 ~ "2",
      CLASIFFICATION_FINAL == 3 ~ "3",
      TRUE ~ "no"
    ),
    covid_tested_degree = factor(covid_tested_degree, levels = c("1", "2", "3", "no"))
  )

# classification analysis
classification_analysis <- kaggle %>%
  summarize(
    total_cases = n(),
    tested_positive = sum(covid_tested),
    tested_negative = sum(!covid_tested),
    positive_rate = mean(covid_tested) * 100
  ) %>%
  mutate(
    across(where(is.numeric), ~round(., 2))
  ) %>%
  kable(col.names = c("Total Cases", "Tested Positive", "Tested Negative", "Positive Rate (%)"),
        caption = "Overall COVID-19 Testing Summary") %>%
  kable_styling()

# Detailed classification table
classification_detail <- kaggle %>%
  count(CLASIFFICATION_FINAL) %>%
  mutate(
    percentage = n/sum(n)*100,
    classification_meaning = case_when(
      CLASIFFICATION_FINAL == 1 ~ "COVID-19 Positive Degree 1",
      CLASIFFICATION_FINAL == 2 ~ "COVID-19 Positive Degree 2",
      CLASIFFICATION_FINAL == 3 ~ "COVID-19 Positive Degree 3",
      TRUE ~ "Negative or Inconclusive"
    )
  ) %>%
  arrange(CLASIFFICATION_FINAL) %>%
  kable(col.names = c("Classification", "Count", "Percentage", "Meaning"),
        digits = 2) %>%
  kable_styling()

# Visualization for covid_tested
covid_tested_plot <- ggplot(kaggle, aes(x = covid_tested, fill = covid_tested)) +
  geom_bar() +
  scale_fill_manual(values = c("TRUE" = "#619CFF", "FALSE" = "#F8766D")) +
  theme_minimal() +
  labs(title = "Distribution of COVID-19 Test Results",
       x = "Tested Positive",
       y = "Count") +
  theme(legend.position = "none")

# Visualization for covid_tested_degree
covid_degree_plot <- ggplot(kaggle, aes(x = covid_tested_degree, fill = covid_tested_degree)) +
  geom_bar() +
  scale_fill_manual(values = c("1" = "#619CFF", "2" = "#36A5FF", "3" = "#1E88E5", "no" = "#F8766D")) +
  theme_minimal() +
  labs(title = "Distribution of COVID-19 Test Degrees",
       x = "Test Degree",
       y = "Count") +
  theme(legend.position = "none")

# Combine plots
classification_plots <- plot_grid(covid_tested_plot, covid_degree_plot, 
                                ncol = 2, labels = "AUTO")

```


### Overall Testing Summary
```{r classification-summary}
classification_analysis
```

### Detailed Classification Distribution
```{r classification-detail}
classification_detail
```

### Visual Distribution of Test Results
```{r classification-plots}
classification_plots
```



# Causal Analysis with DAGs

In this section, we explore the causal relationships between different factors and COVID-19 outcomes. We use Directed Acyclic Graphs (DAGs) to formalize our causal assumptions and guide our analysis.

## DAG Specification and Initial Analysis

First, we create a DAG representing our hypothesized causal relationships. This graph shows how different medical conditions and demographic factors might influence COVID-19 mortality.

```{r setup_dag, message=FALSE, warning=FALSE}
library(dagitty)
library(ggdag)

# Create a DAG for our COVID outcomes
covid_dag <- dagitty('dag {
    Age -> Death
    Age -> Obesity
    Diabetes -> Death
    Diabetes -> Obesity
    Obesity -> Death
    Pneumonia -> Death
    Cardiovascular -> Death
    Hypertension -> Death
    Diabetes -> Hypertension
    Obesity -> Hypertension
    Age -> Hypertension
    Age -> Cardiovascular
    Obesity -> Cardiovascular
}')

# Visualize the DAG
ggdag(covid_dag, text_col='red', stylized = FALSE, label_col='red',
      text_size=2) + 
    theme_dag_blank() +
    labs(title = "Hypothesized Causal Relations for COVID-19 Mortality")
```


The DAG reveals several pathways through which obesity may affect mortality:
- Direct effect: Obesity -> Death
- Via cardiovascular system: Obesity -> Cardiovascular -> Death
- Via blood pressure: Obesity -> Hypertension -> Death
This multiple-pathway structure explains why controlling for mediators (like hypertension) is expected to reduce the total estimated effect.


## Identifying Causal Paths and Adjustment Sets

Next, we examine the paths between key variables and identify proper adjustment sets for causal estimation.

```{r dag_analysis}
# Find all paths from Obesity to Death
paths_obesity_death <- paths(covid_dag, from = "Obesity", to = "Death")

# Create a nice table of paths
tibble(
  Path = unlist(paths_obesity_death)
) %>%
  kable(caption = "All Paths from Obesity to Death") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))

# Identify minimal adjustment sets
adj_sets <- adjustmentSets(covid_dag, exposure = "Obesity", outcome = "Death")

# Create a nice table of adjustment sets
tibble(
  `Adjustment Set` = sapply(adj_sets, paste, collapse = ", ")
) %>%
  kable(caption = "Minimal Adjustment Sets for Estimating Obesity's Effect on Death") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```


The DAG analysis identifies that we need to adjust for **Age** and **Diabetes** to estimate the causal effect of obesity on mortality. This means:

1. Age and diabetes are confounders - they affect both obesity and death risk independently
2. Without adjusting for these variables, our estimate of obesity's effect on death would be biased
3. After adjusting for age and diabetes, any remaining association between obesity and death can be interpreted more causally

This suggests that in our statistical analyses, we should always control for age and diabetes when estimating the effect of obesity on COVID-19 mortality. Other variables like hypertension and cardiovascular disease are potential mediators (they lie on the causal pathway between obesity and death) and should not be adjusted for if we want to estimate the total causal effect of obesity.

```{r adjustment_sets_visual}
# Visualize the adjustment set
ggdag_adjustment_set(covid_dag,
                    exposure = "Obesity",
                    outcome = "Death",
                    text_col = "red",
                    stylized = FALSE,
                    text_size = 2) +
    theme_dag_blank() +
    labs(title = "Minimal Adjustment Set for Obesity -> Death Effect")
```

The visualization highlights our minimal adjustment set (Age and Diabetes) in red. These variables must be controlled for to estimate the causal effect of obesity on mortality. The red paths show the relationship we're interested in (from Obesity to Death), while other paths represent various causal pathways in our model. Variables like Hypertension and Cardiovascular disease are shown in their original color as they are mediators and should not be adjusted for when estimating the total causal effect.

## Testing DAG Implications with Data

Now we'll test whether our data is consistent with the causal assumptions encoded in our DAG.

```{r data_prep}
# Prepare analysis dataset
analysis_data <- model_data %>%
  transmute(
    Death = as.numeric(DIED) - 1,  # Convert to 0/1
    Age = AGE,
    Diabetes = as.numeric(DIABETES),
    Obesity = as.numeric(OBESITY),
    Pneumonia = as.numeric(PNEUMONIA),
    Cardiovascular = as.numeric(CARDIOVASCULAR),
    Hypertension = as.numeric(HIPERTENSION)
  )

# Function to test conditional independence
test_conditional_independence <- function(data, var1, var2, conditioning) {
  formula <- as.formula(paste(var1, "~", var2, "+", 
                            paste(conditioning, collapse = "+")))
  model <- glm(formula, data = data, family = binomial())
  coef_summary <- summary(model)$coefficients
  tibble(
    Variable = var2,
    Estimate = coef_summary[var2, "Estimate"],
    `P-value` = coef_summary[var2, "Pr(>|z|)"]
  )
}

# Test some key relationships
independence_tests <- bind_rows(
  test_conditional_independence(analysis_data, "Death", "Obesity", 
                              c("Age", "Diabetes")),
  test_conditional_independence(analysis_data, "Death", "Hypertension", 
                              c("Age", "Obesity"))
)

independence_tests %>%
  kable(caption = "Tests of Conditional Independence",
        digits = 3) %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

The test results show significant associations (p < 0.001) between:

1. Obesity and Death, even after adjusting for Age and Diabetes, supporting a causal relationship
2. Hypertension and Death, even after adjusting for Age and Obesity, suggesting an independent effect

These results are consistent with our DAG's structure.


## Estimating Causal Effects

Based on the adjustment sets identified by our DAG, we estimate the causal effect of obesity on mortality.

```{r causal_effects}
# Model with minimal adjustment set
model_dag <- glm(Death ~ Obesity + Age + Diabetes,  # minimal adjustment set
                 data = analysis_data, 
                 family = binomial())

# For comparison: Inappropriate model with mediator
model_mediator <- glm(Death ~ Obesity + Age + Diabetes + Hypertension,  # including mediator
                      data = analysis_data, 
                      family = binomial())

# Compare results
bind_rows(
  broom::tidy(model_dag) %>% 
    mutate(model = "DAG-based (correct adjustment)"),
  broom::tidy(model_mediator) %>% 
    mutate(model = "With mediator (over-adjusted)")
) %>%
  filter(term == "Obesity") %>%
  select(model, estimate, std.error, p.value) %>%
  mutate(
    OR = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>%
  kable(caption = "Estimated Causal Effect of Obesity on Mortality",
        digits = 3) %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

## Interpretation

The DAG-based analysis shows that obesity has a significant causal effect on COVID-19 mortality. The properly adjusted model (controlling for age and diabetes) indicates that obesity increases the odds of death by 47% (OR = 1.47, 95% CI: 1.44-1.50). 

When we additionally control for hypertension (a mediator), the estimated effect decreases to 41% (OR = 1.41, 95% CI: 1.38-1.44). This reduction is expected because we're blocking one of the pathways through which obesity affects mortality (via hypertension), thus capturing only part of obesity's total causal effect.

This analysis suggests that obesity has both direct effects on COVID-19 mortality and indirect effects through conditions like hypertension. For public health purposes, the larger total effect (47% increased odds) is most relevant, as it captures the full impact of obesity on COVID-19 mortality risk.


The DAG analysis reveals several important insights:

1. Obesity affects mortality both directly and through multiple indirect paths (via Hypertension and Cardiovascular disease).
2. Age is a key confounder that needs to be adjusted for in any analysis.
3. Different adjustment sets lead to somewhat different effect estimates, highlighting the importance of careful consideration of causal pathways.

## Limitations

This causal analysis has several limitations:
- The DAG represents our assumptions about causal relationships but cannot prove causality.
- We assume no unmeasured confounding.
- The relationships are likely more complex than shown in our simplified DAG.
- Missing data and measurement error could bias our estimates.


# Google Trends Analysis 

To complement our analysis of COVID-19 cases in Mexico, we examine Google search trends that might reflect public interest and concern about the pandemic. We compare search patterns with actual mortality data to understand the relationship between public attention and health outcomes.

## Data Collection

```{r data_gtrends}
library(gtrendsR)

# Define search terms by category
covid_terms <- c(
  # Basic COVID terms
  "COVID México",
  "Coronavirus México",
  "Síntomas COVID",      # COVID symptoms
  "Prueba COVID",        # COVID test
  
  # Vaccination related
  "Vacuna COVID",        # COVID vaccine
  "Registro vacuna COVID", # Vaccine registration
  "Efectos vacuna COVID", # Vaccine side effects
  "Sputnik México",      # Specific vaccines used in Mexico
  "Pfizer México",
  
  # Risk factors and health
  "Obesidad COVID",      # Obesity COVID
  "Diabetes COVID",
  "Hipertensión COVID",
  "Factores de riesgo COVID", # Risk factors COVID
  "Oximetro",           # Oximeter (common purchase during COVID)
  
  # Deaths and burials
  "Muertes COVID México", # COVID deaths
  "Funeraria COVID",     # Funeral homes COVID
  "Cremación COVID",     # Cremation COVID
  
  # Restrictions and prevention
  "Semáforo COVID",      # Mexico's COVID traffic light system
  "Cuarentena México",   # Quarantine
  "Cubrebocas",         # Face masks
  "Gel antibacterial",   # Hand sanitizer
  
  # Economic/Social Impact
  "Apoyo COVID México",  # COVID support/aid
  "Desempleo COVID",     # Unemployment COVID
  "Home office México",
  
  # Treatment
  "Tratamiento COVID",   # COVID treatment
  "Hospital COVID",
  "Tanque oxigeno"      # Oxygen tank (critical during shortages)
)

process_trends <- function(trends_result) {
   trends_result$interest_over_time$hits_num = suppressWarnings(
     trends_result$interest_over_time$hits %>%  
       as.numeric() %>% 
       if_else(is.na(.), 0, .)
     )
    trends_result$interest_over_time %>% mutate(
      date = as.Date(date)
    ) %>% 
   select(-hits)
}


# gtrends call to handle multiple batches
# (limit on simultaneous keywords)
get_trends_batch <- function(keywords, geo, time_range) {
  # Split keywords into batches of 5
  keyword_batches <- split(keywords, ceiling(seq_along(keywords)/5))
  
  # Get trends for each batch
  all_trends <- map(keyword_batches, function(batch) {
    Sys.sleep(1)  # Add delay to avoid API limits
    gtrends(
      keyword = batch,
      time = time_range,
      geo = geo
    )
  })
  
  # Combine results
  #combined_trends <- map_df(all_trends, ~.x$interest_over_time)
  return(all_trends)
}


files$raw <- file.path(dirs$trends, 'trends_covid19_mx.rds')

# Download or load existing data
if (!file.exists(files$raw)) {
  # Download data for Mexico (MX) covering the same period as our case data
  raw_trends <- get_trends_batch(
    keywords = covid_terms,
    geo = "MX",
    time_range = "2020-01-01 2021-05-31"
  )
  
  trends_data <- raw_trends %>%
    map(process_trends) %>%
    bind_rows()
  
  write_rds(trends_data, files$raw)
} else {
  trends_data <- read_rds(files$raw)
}


```

## Data Processing

```{r gtrends_wrangle, fig.height=12}
# Add theme categorization
trends_processed <- trends_data %>%
  mutate(
    theme = case_when(
      keyword %in% c("COVID México", "Coronavirus México", 
                    "Síntomas COVID", "Prueba COVID") ~ "Basic Information",
      keyword %in% c("Vacuna COVID", "Registro vacuna COVID", 
                    "Efectos vacuna COVID", "Sputnik México", 
                    "Pfizer México") ~ "Vaccination",
      keyword %in% c("Obesidad COVID", "Diabetes COVID", 
                    "Hipertensión COVID", "Factores de riesgo COVID", 
                    "Oximetro") ~ "Risk Factors",
      keyword %in% c("Muertes COVID México", "Funeraria COVID", 
                    "Cremación COVID") ~ "Mortality",
      keyword %in% c("Semáforo COVID", "Cuarentena México", 
                    "Cubrebocas", "Gel antibacterial") ~ "Prevention",
      keyword %in% c("Apoyo COVID México", "Desempleo COVID", 
                    "Home office México") ~ "Socioeconomic",
      keyword %in% c("Tratamiento COVID", "Hospital COVID", 
                    "Tanque oxigeno") ~ "Treatment",
      TRUE ~ "Other"
    )
  )

# Create theme-based visualizations
ggplot(trends_processed, 
       aes(x = date, y = hits_num, color = keyword)) +
  geom_line(alpha = 0.7) +
  facet_wrap(~theme, scales = "free_y") +
  theme_minimal() +
  theme(legend.position = "bottom",
        legend.text = element_text(size = 6)) +
  labs(
    title = "COVID-19 Related Google Searches in Mexico by Theme",
    subtitle = "Trends in different aspects of the pandemic",
    y = "Search Interest (0-100)",
    x = "Date"
  )
```

## Comparison of Search Trends and Mortality

Temporal pattern of COVID-19 deaths in Mexico:

```{r mortality_timeline}
mortality_by_month <- kaggle %>%
  filter(DIED) %>%
  mutate(month = floor_date(DATE_DIED, "month")) %>%
  count(month) %>%
  rename(deaths = n)

ggplot(mortality_by_month, aes(x = month, y = deaths)) +
  geom_line(color = "darkred") +
  geom_smooth(method = "loess", se = FALSE, color = "blue") +
  labs(
    title = "COVID-19 Deaths in Mexico",
    subtitle = "Monthly totals with trend line",
    x = "Month",
    y = "Number of Deaths",
    caption = "Data: Mexican Ministry of Health (SALUD)"
  ) +
  theme_minimal()
```

Google search trends:

```{r gtrends_visualization}
# Plot all search terms
ggplot(trends_processed, aes(x = date, y = hits_num, color = keyword)) +
  geom_line() +
  geom_smooth(se = FALSE) +
  theme_minimal() +
  scale_color_viridis_d() +
  labs(
    title = "COVID-19 Related Google Searches in Mexico",
    subtitle = "Relative search volume over time",
    y = "Search Interest (0-100)",
    x = "Date",
    color = "Search Term"
  ) +
  theme(legend.position = "bottom")
```

## Correlation Analysis

We can examine the relationship between search interest and mortality:

```{r correlation_analysis}
## Correlation Analysis

# Create translation dictionary
term_translations <- c(
  "COVID México" = "COVID Mexico",
  "Coronavirus México" = "Coronavirus Mexico",
  "Síntomas COVID" = "COVID symptoms",
  "Prueba COVID" = "COVID test",
  "Vacuna COVID" = "COVID vaccine",
  "Registro vacuna COVID" = "COVID vaccine registration",
  "Efectos vacuna COVID" = "COVID vaccine side effects",
  "Sputnik México" = "Sputnik Mexico",
  "Pfizer México" = "Pfizer Mexico",
  "Obesidad COVID" = "COVID obesity",
  "Diabetes COVID" = "COVID diabetes",
  "Hipertensión COVID" = "COVID hypertension",
  "Factores de riesgo COVID" = "COVID risk factors",
  "Oximetro" = "Oximeter",
  "Muertes COVID México" = "COVID deaths Mexico",
  "Funeraria COVID" = "COVID funeral homes",
  "Cremación COVID" = "COVID cremation",
  "Semáforo COVID" = "COVID traffic light system",
  "Cuarentena México" = "Quarantine Mexico",
  "Cubrebocas" = "Face masks",
  "Gel antibacterial" = "Hand sanitizer",
  "Apoyo COVID México" = "COVID support Mexico",
  "Desempleo COVID" = "COVID unemployment",
  "Home office México" = "Home office Mexico",
  "Tratamiento COVID" = "COVID treatment",
  "Hospital COVID" = "COVID hospital",
  "Tanque oxigeno" = "Oxygen tank"
)

# Aggregate search data by month for comparison
search_by_month <- trends_processed %>%
  mutate(month = floor_date(date, "month")) %>%
  group_by(month, keyword) %>%
  summarize(mean_interest = mean(hits_num, na.rm = TRUE), .groups = "drop")

# Join with mortality data
combined_data <- search_by_month %>%
  inner_join(mortality_by_month, by = "month")

# Calculate correlations with error handling
correlations <- combined_data %>%
  group_by(keyword) %>%
  summarize(
    correlation = tryCatch(
      cor(mean_interest, deaths, use = "complete.obs"),
      warning = function(w) NA_real_
    ),
    p_value = tryCatch(
      cor.test(mean_interest, deaths)$p.value,
      warning = function(w) NA_real_,
      error = function(e) NA_real_
    ),
    sd_interest = sd(mean_interest, na.rm = TRUE)  # Add SD to check variation
  ) %>%
  filter(!is.na(correlation)) %>%  # Remove terms with no correlation
  filter(sd_interest > 0) %>%      # Remove terms with no variation
  mutate(
    keyword_en = term_translations[keyword],  # Add English translations
    significance = case_when(
      p_value < 0.001 ~ "***",
      p_value < 0.01 ~ "**",
      p_value < 0.05 ~ "*",
      TRUE ~ "ns"
    )
  ) %>%
  arrange(desc(abs(correlation)))

# Display correlations
correlations %>%
  select(
    `Search Term (Spanish)` = keyword,
    `Search Term (English)` = keyword_en,
    `Correlation` = correlation,
    `P-value` = p_value,
    `Significance` = significance
  ) %>%
  mutate(
    across(c(Correlation, `P-value`), ~round(., 3))
  ) %>%
  kable(caption = "Correlations between Search Interest and COVID-19 Deaths") %>%
  kable_styling(bootstrap_options = c("striped", "hover"))
```

## Interpretation

The analysis reveals several interesting patterns in the relationship between Google searches and COVID-19 mortality in Mexico:

1. **Strong Positive Correlations** (r > 0.6, p < 0.01):
   - Unemployment searches showed the strongest correlation (r = 0.900), suggesting a strong parallel between the health and economic impact of the pandemic
   - Searches for risk factors (r = 0.815) increased alongside mortality, indicating growing public health awareness
   - Death-related searches (r = 0.635) and face mask queries (r = 0.632) closely tracked actual mortality patterns

2. **Moderate Correlations** (0.3 < r < 0.6, not significant):
   - Health-related terms like symptoms, hospital information, and oximeter showed moderate positive correlations
   - These patterns suggest ongoing public health information seeking throughout the pandemic

3. **Vaccine-Related Patterns**:
   - Interestingly, vaccine-related searches showed negative correlations with mortality
   - This might reflect the timing of vaccination campaigns, which began as mortality rates were declining
   - The negative correlations for vaccine side effects (-0.345) and registration (-0.267) suggest these became prominent topics in later phases of the pandemic

4. **Prevention and Treatment**:
   - Basic prevention terms (hand sanitizer, face masks) showed varying correlations
   - Treatment-related searches showed weak to moderate correlations, possibly indicating consistent information seeking regardless of mortality rates

## Limitations

- Google Trends data represents only internet users, which might not be representative of the entire Mexican population, particularly in rural or less connected areas
- Search patterns might be influenced by media coverage and public health campaigns rather than direct experience with COVID-19
- The relative nature of Google Trends data (0-100 scale) makes absolute comparisons between terms difficult
- Search behavior might differ across regions within Mexico, while our mortality data is national
- Correlation doesn't imply causation; many other factors influence both search behavior and mortality rates
- Some important search terms might show no variation (zero standard deviation) and were thus excluded from the analysis
- The timing of searches might reflect both anticipatory behavior (searching before getting sick) and reactive behavior (searching after infection)

## Time Series Analysis of Search Trends

To better understand the temporal patterns in COVID-19 related searches, we perform a time series decomposition and impact analysis focusing on the initial pandemic period.

### Seasonal Decomposition

First, let's examine the underlying patterns in search behavior before the pandemic:

```{r ts_decomposition}
library(forecast)
library(jtools)  # for summ function

# Create time series for pre-pandemic period
ts_in <- trends_processed %>%
  filter(date >= '2020-01-01' & date <= '2021-05-31',
         keyword == "COVID México") %>%  # or another key term
  arrange(date) %>%
  select(hits_num) %>%
  pull()

covid_ts <- ts(ts_in, start = c(2019, 1), frequency = 12)

# Decompose the time series
dcp <- mstl(covid_ts, s.window = "periodic")

# Plot decomposition
autoplot(dcp) +
  labs(title = "Multiple Seasonal Decomposition of COVID-19 Search Queries",
       subtitle = "Trend, Seasonal, and Random Components")

# Check autocorrelation
ggAcf(covid_ts) +
  labs(title = "Autocorrelation Plot (COVID-19 Search Queries)")
```

### Impact Analysis

We now assess whether specific events (like lockdown implementation) are statistically associated with changes in search patterns:

```{r impact_analysis}
# Prepare data for impact analysis
data_impact <- trends_processed %>%
  filter(keyword == "COVID México",  # or another key term
         date <= '2021-05-31') %>%
  arrange(date) %>%
  mutate(
    time = row_number() - 1,  # time index starting at 0
    month = as.factor(month(date)),
    hits_l1 = lag(hits_num),
    # Define treatment period (e.g., first major outbreak or lockdown)
    after = if_else(date >= as.Date('2020-03-01'), 1, 0),
    tau = min(ifelse(after == 1, time, NA_integer_), na.rm = TRUE),
    time_diff = time - tau,
    A_TimeDiff = after * time_diff
  )

# Fit segmented regression
lm_out <- lm(log(hits_num + 1) ~ time + month + after + A_TimeDiff, 
             data = data_impact)

# Calculate percentage change
ipct_out <- round(exp(coef(lm_out)["A_TimeDiff"]) * 100 - 100, 3)

# Display results with Newey-West standard errors
summ(lm_out, 
     vcov = NeweyWest(lm_out, lag = 3, prewhite = TRUE, adjust = TRUE), 
     digits = 3)
```
### Interpretation of Time Series Analysis

The decomposition and regression analysis reveal several key patterns in COVID-19 related searches:

1. **Trend Component**: 
   - The data shows a sharp increase in early 2020, coinciding with the pandemic's onset
   - After the initial spike, search interest stabilized at a higher level than pre-pandemic
   - A gradual declining trend is visible from 2022 onwards

2. **Seasonal Pattern**:
   - Clear monthly seasonality is present in the data
   - Strongest negative seasonal effects in late summer/fall (August-November)
   - The seasonal component shows regular fluctuations with approximately 0.6 unit amplitude

3. **Impact Analysis Results**:
   - **Immediate Effect**: A significant level shift occurred after the intervention (β = 1.220, p = 0.003), indicating an immediate 239% increase (e^1.220 - 1) in search intensity
   - **Trend Change**: The negative interaction term (β = -0.057, p = 0.028) suggests a gradual decline in the intervention effect over time
   - **Monthly Effects**: Strongest seasonal decreases in August through November (significant at p < 0.01)
   - The model explains a substantial portion of the variance (R² = 0.773)

4. **Autocorrelation Structure**:
   - Strong positive autocorrelation in the first 4-5 lags
   - Negative autocorrelation at longer lags
   - This pattern suggests short-term persistence in search behavior followed by periodic reversals

### Practical Implications

1. **Public Health Communication**:
   - The strong immediate effect suggests high initial public interest/concern
   - The declining trend indicates a possible "pandemic fatigue" in information seeking
   - Seasonal patterns could be used to time public health messaging

2. **Policy Relevance**:
   - The gradual decline in effect (-5.7% per month) suggests a normalization of information-seeking behavior
   - Seasonal variations should be considered when interpreting search patterns
   - The high R² indicates that the model captures the major drivers of search behavior

### Limitations

- The analysis period might be too short to establish robust seasonal patterns
- The model assumes linear trends which might not fully capture the complexity of public response
- Search patterns might reflect media coverage rather than actual health concerns
- The presence of strong autocorrelation suggests possible omitted time-varying factors

